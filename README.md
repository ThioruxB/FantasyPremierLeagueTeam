# âš½ ConectPremier: Fantasy Premier League AI Assistant

![Project Status](https://img.shields.io/badge/status-active-success.svg)
![Python Version](https://img.shields.io/badge/python-3.8%2B-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

**ConectPremier** es un sistema avanzado de anÃ¡lisis de datos y machine learning diseÃ±ado para revolucionar la toma de decisiones en la Fantasy Premier League (FPL). Utilizando algoritmos de optimizaciÃ³n matemÃ¡tica y modelos predictivos de Ãºltima generaciÃ³n, este proyecto ofrece a los managers una ventaja competitiva basada en datos.

<table>
  <tr>
    <td align="center"><b>Dashboard de AnÃ¡lisis</b></td>
    <td align="center"><b>Detalle de Jugadores</b></td>
  </tr>
  <tr>
    <td><img src="data/output/eda.html" alt="Dashboard Demo" width="420"></td>
    <td><img src="img/demos2.png" alt="Player Detail Demo" width="420"></td>
  </tr>
</table>

---

## ğŸš€ CaracterÃ­sticas Principales

*   **ğŸ”® PredicciÃ³n de Puntos Esperados (xP)**: Modelo de Gradient Boosting entrenado con datos histÃ³ricos para predecir el rendimiento futuro de cada jugador.
*   **ğŸ§  OptimizaciÃ³n de Plantilla (ILP)**: Algoritmos de ProgramaciÃ³n Lineal Entera (PuLP) para seleccionar el equipo matemÃ¡ticamente Ã³ptimo bajo las restricciones de presupuesto y reglas de la FPL.
*   **ğŸ² SimulaciÃ³n de Monte Carlo**: AnÃ¡lisis de robustez que simula miles de escenarios para recomendar equipos que no solo son buenos en promedio, sino consistentes y de bajo riesgo.
*   **ğŸ”„ Pipeline ETL Automatizado**: ExtracciÃ³n, transformaciÃ³n y carga de datos desde la API oficial de la FPL y fuentes externas (WhoScored) de forma totalmente automatizada.
*   **ğŸ“Š AnÃ¡lisis de Volatilidad**: MÃ©tricas avanzadas para evaluar la consistencia de los jugadores y evitar "trampas" de puntos.

---

## ğŸ“‚ Estructura del Proyecto

El proyecto ha sido reorganizado para seguir las mejores prÃ¡cticas de ingenierÃ­a de software:

```text
ConectPremier/
â”œâ”€â”€ ğŸ“ data/                  # Almacenamiento de datos
â”‚   â”œâ”€â”€ ğŸ“ raw/               # Datos crudos (CSVs, JSONs de la API)
â”‚   â”œâ”€â”€ ğŸ“ processed/         # Datos limpios y enriquecidos para el modelo
â”‚   â””â”€â”€ ğŸ“ output/            # Reportes generados, grÃ¡ficos y logs
â”œâ”€â”€ ğŸ“ scripts/               # Scripts utilitarios y de ejecuciÃ³n
â”‚   â”œâ”€â”€ ğŸ“ etl/               # Scripts de limpieza y carga de datos
â”‚   â”œâ”€â”€ ğŸ“ scraping/          # Scrapers para obtener datos externos
â”‚   â”œâ”€â”€ ğŸ“ analysis/          # Scripts de anÃ¡lisis exploratorio (EDA)
â”‚   â””â”€â”€ ğŸ“ web/               # Scripts para la interfaz web
â”œâ”€â”€ ğŸ“ src/                   # CÃ³digo fuente principal (Core Logic)
â”‚   â”œâ”€â”€ data_pipeline.py      # Orquestador del flujo de datos
â”‚   â”œâ”€â”€ feature_engineering.py# IngenierÃ­a de caracterÃ­sticas
â”‚   â”œâ”€â”€ model_training.py     # Entrenamiento del modelo predictivo
â”‚   â””â”€â”€ team_selection.py     # LÃ³gica de optimizaciÃ³n de equipos
â”œâ”€â”€ ğŸ“ sql/                   # Scripts SQL para gestiÃ³n de base de datos
â”œâ”€â”€ ğŸ“ web/                   # Interfaz web (HTML/JS)
â”œâ”€â”€ ğŸ“ notebooks/             # Jupyter Notebooks para experimentaciÃ³n
â””â”€â”€ ğŸ“„ run_project.py         # Punto de entrada principal
```

---

## ğŸ› ï¸ InstalaciÃ³n y ConfiguraciÃ³n

### Prerrequisitos

*   Python 3.8 o superior
*   PostgreSQL (Base de datos)
*   Cuenta de Neon Tech (Opcional, si se usa la configuraciÃ³n por defecto)

### Pasos de InstalaciÃ³n

1.  **Clonar el repositorio:**
    ```bash
    git clone https://github.com/tu-usuario/ConectPremier.git
    cd ConectPremier
    ```

2.  **Crear un entorno virtual (Recomendado):**
    ```bash
    python -m venv venv
    # En Windows:
    .\venv\Scripts\activate
    # En macOS/Linux:
    source venv/bin/activate
    ```

3.  **Instalar dependencias:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Configurar Variables de Entorno:**
    Crea un archivo `.env` o configura tus variables de entorno para la conexiÃ³n a la base de datos:
    ```env
    DB_CONNECTION_STRING=postgresql://usuario:password@host/dbname
    ```

<<<<<<< HEAD
### Scraping de Datos de Partidos

El proyecto tambiÃ©n incluye un script para realizar web scraping de datos detallados de un partido desde WhoScored.com y cargarlos en la base de datos.

-   **Fuente de Datos**: `pag3.json`, que contiene los datos de un partido.
-   **Script**: `insert_data_to_db.py`

Para ejecutar este proceso, utiliza el siguiente comando:

```bash
python insert_data_to_db.py
```

## Base de Datos

El sistema utiliza una base de datos PostgreSQL, alojada en [Neon](https://neon.tech/), para almacenar los datos histÃ³ricos de jugadores y equipos. La configuraciÃ³n de la conexiÃ³n estÃ¡ definida directamente en los scripts de la carpeta `src`. Si deseas utilizar tu propia base de datos, deberÃ¡s actualizar la cadena de conexiÃ³n en dichos archivos.

### Scripts de Datos HistÃ³ricos

Adicionalmente, se han aÃ±adido scripts para trabajar con datos histÃ³ricos de los jugadores:

-   `scripts/get_all_players_history_resumable.py`: Extrae de la API de FPL las estadÃ­sticas agregadas de las Ãºltimas dos temporadas de la carrera de cada jugador y las guarda en `all_players_history_resumable.csv`. El script es reanudable.
-   `scripts/upload_season_history.py`: Sube los datos del CSV anterior a una tabla `player_season_history` en la base de datos, diseÃ±ada para almacenar este historial.

=======
>>>>>>> 28b92f7 (ActualizaciÃ³n del proyecto)
---

## ğŸ’» GuÃ­a de Uso

### 1. EjecuciÃ³n Completa (Recomendado)
Para correr todo el pipeline (descarga de datos, procesamiento, entrenamiento y recomendaciÃ³n):

```bash
python run_project.py
```

### 2. RecomendaciÃ³n RÃ¡pida
Si ya tienes los datos procesados y solo quieres generar una nueva recomendaciÃ³n de equipo:

```bash
python recommend_team.py
```

### 3. ActualizaciÃ³n de Datos Externos
Para actualizar la base de datos con los Ãºltimos partidos y estadÃ­sticas de WhoScored:

```bash
python run_update.py
```

---

## ğŸ“Š Flujo de Datos y MetodologÃ­a

1.  **Ingesta**: `scripts/scraping/scrape_soccerdata.py` y `src/data_pipeline.py` obtienen datos crudos.
2.  **Procesamiento**: `scripts/etl/clean_data.py` limpia y normaliza los datos.
3.  **IngenierÃ­a de CaracterÃ­sticas**: `src/feature_engineering.py` calcula mÃ©tricas clave como *Forma*, *Dificultad de Calendario* y *Volatilidad*.
4.  **Modelado**: `src/model_training.py` entrena un modelo Gradient Boosting para predecir puntos.
5.  **OptimizaciÃ³n**: `src/team_selection.py` utiliza PuLP para resolver el problema de la mochila (Knapsack Problem) aplicado a la FPL.

---

## ğŸ—„ï¸ Esquema de Base de Datos

El sistema utiliza un esquema relacional robusto en PostgreSQL:

*   **`players`**: InformaciÃ³n estÃ¡tica de los jugadores.
*   **`teams`**: Datos de los equipos de la Premier League.
*   **`fixtures`**: Calendario de partidos y resultados.
*   **`player_history`**: Rendimiento histÃ³rico partido a partido.
*   **`gameweeks`**: InformaciÃ³n sobre las jornadas de la FPL.

---

## ğŸ¤ ContribuciÃ³n

Â¡Las contribuciones son bienvenidas! Si tienes ideas para mejorar el modelo o nuevas caracterÃ­sticas:

1.  Haz un Fork del proyecto.
2.  Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`).
3.  Haz Commit de tus cambios (`git commit -m 'Add some AmazingFeature'`).
4.  Haz Push a la rama (`git push origin feature/AmazingFeature`).
5.  Abre un Pull Request.

---

## ğŸ“„ Licencia

Distribuido bajo la licencia MIT. Ver `LICENSE` para mÃ¡s informaciÃ³n.

---

<div align="center">
  <sub>Construido con â¤ï¸ por el equipo de ConectPremier</sub>
</div>